# 堆和栈的区别
**堆**
堆是无序的，是一片不连续的内存域，由用户自己来控制和释放，如果用户自己不释放的话，当内存达到一定的特定值时或程序运行结束时，通过垃圾回收器（GC）来回收。

是程序运行期间动态分配的内存空间，你可以根据程序的运行情况确定要分配的堆内存的大小。
**栈**
栈是有顺序的，是一片连续的内存域，保持着先进后出的原则，由系统自动分配和维护。

是编译期间就分配好的内存空间，因此代码中必须就栈的大小有明确的定义。即， 所分配的内存是在一块连续的内存区域内．当我们声明变量时，那么编译器会自动接着当前栈区的结尾来分配内存。

**堆栈空间分配**

 栈（操作系统）：由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。

 堆（操作系统）： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收，分配方式倒是类似于链表。

**堆栈缓存方式**

栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放。

堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些。

- 堆中会有值类型吗
会， 数组可以声明在堆中 当数组中的值为值类型即存在堆中具有值类型
https://stackoverflow.com/questions/1113819/arrays-heap-and-stack-and-value-types
```c++
int a[100] = {0}; // 这是在栈中的
int a[100] = malloc(sizeof(int)*100); // 这是在堆中的
```

# 多线程多进程 协程 并发 并行 高并发
**进程**

进程，就是这种“程序切换”的第一种方式。

定义

进程，是执行中的计算机程序。也就是说，每个代码在执行的时候，首先本身即是一个进程。

一个进程具有：就绪，运行，中断，僵死，结束等状态（不同操作系统不一样）。

使用

用户编写代码(代码本身是以进程运行的)
启动程序，进入进程“就绪”状态
操作系统调度资源，做“程序切换”，使得进程进入“运行”状态
结束/中断

程序执行完，则进入“结束”状态
程序未执行完，但操作系统达到“程序切换”的要求，进入“中断”状态，等待下次被调度后执行


特性

每个程序，本身首先是一个进程
运行中每个进程都拥有自己的地址空间、内存、数据栈及其它资源。
操作系统本身自动管理着所有的进程(不需要用户代码干涉)，并为这些进程合理分配可以执行时间。
进程可以通过派生新的进程来执行其它任务，不过每个进程还是都拥有自己的内存和数据栈等。
进程间可以通讯(发消息和数据)，采用 进程间通信(IPC) 方式。
说明

多个进程可以在不同的 CPU 上运行，互不干扰
同一个CPU上，可以运行多个进程，由操作系统来自动分配时间片
由于进程间资源不能共享，需要进程间通信，来发送数据，接受消息等
多进程，也称为“并行”。
**线程**

线程，也是“程序切换”的一种方式。

定义

线程，是在进程中执行的代码。

一个进程下可以运行多个线程，这些线程之间共享主进程内申请的操作系统资源。

在一个进程中启动多个线程的时候，每个线程按照顺序执行。现在的操作系统中，也支持线程抢占，也就是说其它等待运行的线程，可以通过优先级，信号等方式，将运行的线程挂起，自己先运行。

使用

用户编写包含线程的程序(每个程序本身都是一个进程)
操作系统“程序切换”进入当前进程
当前进程包含了线程，则启动线程
多个线程，则按照顺序执行，除非抢占
特性

线程，必须在一个存在的进程中启动运行
线程使用进程获得的系统资源，不会像进程那样需要申请CPU等资源
线程无法给予公平执行时间，它可以被其他线程抢占，而进程按照操作系统的设定分配执行时间
每个进程中，都可以启动很多个线程
说明

多线程，也被称为”并发“执行。

**协程**

协程，也是”程序切换“的一种。

这里提一个特殊的“线程”，也就是协程的概念。

定义

简单说，协程也是线程，只是协程的调度并不是由操作系统调度，而是自己”协同调度“。也就是”协程是不通过操作系统调度的线程“。当然，实际要比这更复杂一些，本课程不研究协程技术，对于这个很有挑战的技术，在我们完全掌握了进程线程后，自然会理解问题渊源。

协程，又称微线程。

说明

协程的主要特色是：

协程间是协同调度的，这使得并发量数万以上的时候，协程的性能是远远高于线程。
注意这里也是“并发”，不是“并行”。

**并发（concurrency）**

要理解“并发”这个概念，必须得清楚，并发指的是程序的“结构”。当我们说这个程序是并发的，实际上，这句话应当表述成“这个程序采用了支持并发的设计”。好，既然并发指的是人为设计的结构，那么怎样的程序结构才叫做支持并发的设计？

正确的并发设计的标准是：使多个操作可以在重叠的时间段内进行(two tasks can start, run, and complete in overlapping time periods)。

这句话的重点有两个。我们先看“（操作）在重叠的时间段内进行”这个概念。它是否就是我们前面说到的并行呢？是，也不是。并行，当然是在重叠的时间段内执行，但是另外一种执行模式，也属于在重叠时间段内进行。这就是协程。

使用协程时，程序的执行看起来往往是这个样子：

![image.png](https://i.loli.net/2021/07/28/6yfKUGIBJzkNusW.png)

task1, task2 是两段不同的代码，比如两个函数，其中黑色块代表某段代码正在执行。注意，这里从始至终，在任何一个时间点上都只有一段代码在执行，但是，由于 task1 和 task2 在重叠的时间段内执行，所以这是一个支持并发的设计。与并行不同，单核单线程能支持并发。

经常看到这样一个说法，叫做并发执行。现在我们可以正确理解它。有两种可能：

原本想说的是“并行执行”，但是用错了词
指多个操作可以在重叠的时间段内进行，即，真的并行，或是类似上图那样的执行模式。
我的建议是尽可能不使用这个词，容易造成误会，尤其是对那些并发并行不分的人。但是读到这里的各位显然能正确区分，所以下面为了简便，将使用并发执行这个词。

第二个重点是“可以在重叠的时间段内进行”中的“可以”两个字。“可以”的意思是，正确的并发设计使并发执行成为可能，但是程序在实际运行时却不一定会出现多个任务执行时间段 overlap 的情形。比如：我们的程序会为每个任务开一个线程或者协程，只有一个任务时，显然不会出现多个任务执行时间段重叠的情况，有多个任务时，就会出现了。这里我们看到，并发并不描述程序执行的状态，它描述的是一种设计，是程序的结构，比如上面例子里“为每个任务开一个线程”的设计。并发设计和程序实际执行情况没有直接关联，但是正确的并发设计让并发执行成为可能。反之，如果程序被设计为执行完一个任务再接着执行下一个，那就不是并发设计了，因为做不到并发执行。

那么，如何实现支持并发的设计？两个字：拆分。

之所以并发设计往往需要把流程拆开，是因为如果不拆分也就不可能在同一时间段进行多个任务了。这种拆分可以是平行的拆分，比如抽象成同类的任务，也可以是不平行的，比如分为多个步骤。

**并行（parallelism）**
这个概念很好理解。所谓并行，就是同时执行的意思，无需过度解读。判断程序是否处于并行的状态，就看同一时刻是否有超过一个“工作单位”在运行就好了。所以，单线程永远无法达到并行状态。

要达到并行状态，最简单的就是利用多线程和多进程。但是 Python 的多线程由于存在著名的 GIL，无法让两个线程真正“同时运行”，所以实际上是无法到达并行状态的。

**并发并行的关系**
并发设计让并发执行成为可能，而并行是并发执行的一种模式。
refer：https://laike9m.com/blog/huan-zai-yi-huo-bing-fa-he-bing-xing,61/

# 银行家算法
https://www.cnblogs.com/wkfvawl/p/11598647.html
## 死锁
死锁 :是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去
（1） 因为系统资源不足。
（2） 进程运行推进顺序不合适。
（3） 资源分配不当等。
如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则
就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。
（1） 互斥条件：一个资源每次只能被一个进程使用。
（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之
一不满足，就不会发生死锁。
死锁的解除与预防：
理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和
解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确
定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态
的情况下占用资源。因此，对资源的分配要给予合理的规划。

进程A占有对象1的锁，进程B占有对象2的锁，进程A需要对象2的锁才能继续执行，所以进程A会等待进程B释放对象2的锁，而进程B需要对象1的锁才能继续执行，同样会等待进程A释放对象1的锁，由于这两个进程都不释放已占有的锁，所以导致他们进入无限等待中
```c++
当线程1和2都已经成功获取到第一个锁时，死锁就发生了。
//线程1
Synchorized（objectA）｛
    Synchorized（objectB）｛
        //操作
 
    ｝
｝

//线程2 
Synchorized（objectB）｛ 
    Synchorized（objectA）｛ 
        //操作
 
    ｝ 
｝
```
*面试时就说你录用我我就告诉你什么是死锁，对面说你告诉我我再录用你*